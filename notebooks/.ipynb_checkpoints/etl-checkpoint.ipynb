{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dddf01b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-16T08:26:32.067715Z",
     "start_time": "2022-04-16T08:26:31.530168Z"
    }
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c619b146",
   "metadata": {},
   "source": [
    "# Create Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8492649b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-16T08:26:32.076080Z",
     "start_time": "2022-04-16T08:26:32.072868Z"
    }
   },
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"../data/research.db\")\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdd608e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-16T08:26:32.131814Z",
     "start_time": "2022-04-16T08:26:32.077921Z"
    }
   },
   "outputs": [],
   "source": [
    "drop_table_queries = ['research_profile', 'author', 'school',\n",
    "                      'sdg', 'neda', 'journal', 'budget_source',\n",
    "                      'funding_agency', 'funding_type', 'research_status']\n",
    "\n",
    "drop_table_queries = list(map(lambda x: f'DROP TABLE IF EXISTS {x};', \n",
    "                              drop_table_queries))\n",
    "\n",
    "def drop_tables(cur, conn):\n",
    "    for query in drop_table_queries:\n",
    "        cur.execute(query)\n",
    "        conn.commit()\n",
    "\n",
    "drop_tables(cur, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5b95f24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-16T08:26:32.174689Z",
     "start_time": "2022-04-16T08:26:32.134068Z"
    }
   },
   "outputs": [],
   "source": [
    "author_create = (\"\"\"\n",
    "CREATE TABLE author (\n",
    "    author_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    author_name VARCHAR NOT NULL UNIQUE \n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "sdg_create = (\"\"\"\n",
    "CREATE TABLE sdg (\n",
    "    sdg_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    sdg_name VARCHAR NOT NULL UNIQUE\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "neda_create = (\"\"\"\n",
    "CREATE TABLE neda (\n",
    "    neda_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    neda_name VARCHAR NOT NULL UNIQUE \n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "journal_create = (\"\"\"\n",
    "CREATE TABLE journal (\n",
    "    journal_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    journal_name VARCHAR NOT NULL,\n",
    "    volume_no VARCHAR,\n",
    "    issue_no VARCHAR,\n",
    "    year_published INTEGER,\n",
    "    no_citations INTEGER,\n",
    "    scope VARCHAR\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "rs_create = (\"\"\"\n",
    "CREATE TABLE research_status (\n",
    "    rs_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    rs_name VARCHAR NOT NULL UNIQUE\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "school_create = (\"\"\"\n",
    "CREATE TABLE school (\n",
    "    school_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    school_name VARCHAR NOT NULL,\n",
    "    school_abbreviation VARCHAR,\n",
    "    campus VARCHAR, \n",
    "    city VARCHAR, \n",
    "    province VARCHAR, \n",
    "    region VARCHAR\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "bs_create = (\"\"\"\n",
    "CREATE TABLE budget_source (\n",
    "    bs_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    bs_name VARCHAR NOT NULL UNIQUE\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "fa_create = (\"\"\"\n",
    "CREATE TABLE funding_agency (\n",
    "    fa_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    fa_name VARCHAR NOT NULL UNIQUE \n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "ft_create = (\"\"\"\n",
    "CREATE TABLE funding_type (\n",
    "    ft_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    ft_name VARCHAR NOT NULL UNIQUE \n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "research_profile_create = (\"\"\"\n",
    "CREATE TABLE research_profile (\n",
    "    research_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    research_title VARCHAR NOT NULL, \n",
    "    author_id INTEGER NOT NULL, \n",
    "    keywords VARCHAR,\n",
    "    abstract VARCHAR, \n",
    "    year INTEGER, \n",
    "    school_id INTEGER, \n",
    "    sdg_id INTEGER,\n",
    "    neda_id INTEGER, \n",
    "    journal_id INTEGER, \n",
    "    allocated_budget INTEGER, \n",
    "    bs_id INTEGER, \n",
    "    fa_id INTEGER, \n",
    "    ft_id INTEGER, \n",
    "    rs_id INTEGER,\n",
    "    CONSTRAINT fk_author \n",
    "        FOREIGN KEY (author_id)\n",
    "        REFERENCES author(author_id), \n",
    "    CONSTRAINT fk_sdg\n",
    "        FOREIGN KEY (sdg_id)\n",
    "        REFERENCES sdg(sdg_id),\n",
    "    CONSTRAINT fk_neda\n",
    "        FOREIGN KEY (neda_id)\n",
    "        REFERENCES neda(neda_id),\n",
    "    CONSTRAINT fk_journal\n",
    "        FOREIGN KEY (journal_id)\n",
    "        REFERENCES journal(journal_id),\n",
    "    CONSTRAINT fk_school\n",
    "        FOREIGN KEY (school_id)\n",
    "        REFERENCES school(school_id),\n",
    "    CONSTRAINT fk_bs\n",
    "        FOREIGN KEY (bs_id)\n",
    "        REFERENCES budget_source(bs_id),\n",
    "    CONSTRAINT fk_fa\n",
    "        FOREIGN KEY (fa_id)\n",
    "        REFERENCES funding_agency(fa_id),\n",
    "    CONSTRAINT fk_ft\n",
    "        FOREIGN KEY (ft_id)\n",
    "        REFERENCES funding_type(ft_id),\n",
    "    CONSTRAINT fk_rs\n",
    "        FOREIGN KEY (rs_id)\n",
    "        REFERENCES research_status(rs_id)\n",
    "    \n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "\n",
    "create_table_queries = [author_create, sdg_create, \n",
    "                        neda_create, journal_create, \n",
    "                        rs_create, school_create, \n",
    "                        bs_create, fa_create, ft_create,  \n",
    "                        research_profile_create]\n",
    "\n",
    "def create_tables(cur, conn):\n",
    "    for query in create_table_queries:\n",
    "        cur.execute(query)\n",
    "        conn.commit()\n",
    "    \n",
    "create_tables(cur, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d418b6c",
   "metadata": {},
   "source": [
    "# ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dfbcae6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-16T08:26:32.800544Z",
     "start_time": "2022-04-16T08:26:32.177031Z"
    }
   },
   "outputs": [],
   "source": [
    "res_prof = pd.read_excel('../data/cleaned/research_profile.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5fad74d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-16T08:26:32.809166Z",
     "start_time": "2022-04-16T08:26:32.802919Z"
    }
   },
   "outputs": [],
   "source": [
    "def check_author_similarity(unique_authors):\n",
    "    one_step_authors = unique_authors[1:]\n",
    "    replace_authors = {}\n",
    "    for author, step_author in zip(unique_authors, one_step_authors):\n",
    "        count = 0\n",
    "        for (name_author, \n",
    "             name_step) in zip(list(map(lambda x: x.strip(), author.split())),\n",
    "                           list(map(lambda x: x.strip(), step_author.split()))\n",
    "                            ):\n",
    "\n",
    "            if name_author == name_step:\n",
    "                count += 1\n",
    "\n",
    "        if count >= 2:\n",
    "            if len(author) < len(step_author):\n",
    "                replace_authors[step_author] = author\n",
    "            else:\n",
    "                replace_authors[author] = step_author\n",
    "    \n",
    "    return replace_authors\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c847f31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-16T08:26:33.890146Z",
     "start_time": "2022-04-16T08:26:32.811048Z"
    }
   },
   "outputs": [],
   "source": [
    "author_insert = \"\"\"\n",
    "INSERT INTO author (author_name)\n",
    "VALUES (?)\n",
    "\"\"\"\n",
    "\n",
    "def process_author(cur, conn, res_prof):\n",
    "    unique_authors = sorted(res_prof['Author'].str.split(';')\n",
    "                                              .explode().unique())\n",
    "    unique_authors.remove('')\n",
    "    unique_authors.remove(',')\n",
    "    while check_author_similarity(unique_authors):\n",
    "        for key, item in check_author_similarity(unique_authors).items():\n",
    "            res_prof['Author'] = (res_prof['Author'].str.replace(key, item, \n",
    "                                                                regex=False)\n",
    "                                           .apply(lambda x: x if x[-1] != ';' \n",
    "                                                  else x[:-1])\n",
    "                                           .str.replace(';;', ';',\n",
    "                                                        regex=False))\n",
    "                            \n",
    "            unique_authors = sorted(res_prof['Author']\n",
    "                                    .str.split(';')\n",
    "                                    .explode().unique())\n",
    "            try:\n",
    "                unique_authors.remove('')\n",
    "                unique_authors.remove(',')\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    \n",
    "    for author in unique_authors:\n",
    "        cur.execute(author_insert, tuple([author]))\n",
    "        \n",
    "    conn.commit()\n",
    "    \n",
    "    res_prof['Author'] = res_prof['Author'].str.split(';')\n",
    "    res_prof = res_prof.explode('Author')\n",
    "    cur.execute('SELECT * FROM author;')\n",
    "    author_table = pd.DataFrame(cur.fetchall(), columns=['author_id',\n",
    "                                                         'author'])\n",
    "    res_prof = pd.merge(res_prof, author_table, \n",
    "                        left_on='Author', \n",
    "                        right_on='author', \n",
    "                        how='left')\n",
    "\n",
    "    res_prof = res_prof.drop(['author', 'Author'], axis=1)\n",
    "    \n",
    "    return res_prof\n",
    "    \n",
    "res_prof = process_author(cur, conn, res_prof)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb8f616a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-16T08:26:33.930008Z",
     "start_time": "2022-04-16T08:26:33.896084Z"
    }
   },
   "outputs": [],
   "source": [
    "sdg_insert = \"\"\"\n",
    "INSERT INTO sdg (sdg_id, sdg_name)\n",
    "VALUES (?, ?)\n",
    "\"\"\"\n",
    "\n",
    "def process_sdg(cur, conn, res_prof):\n",
    "    sdg_mapping = [\n",
    "        [1, 'No poverty'],\n",
    "        [2, 'Zero hunger'],\n",
    "        [3, 'Good health and well-being'],\n",
    "        [4, 'Quality education'],\n",
    "        [5, 'Gender equality'],\n",
    "        [6, 'Clean water and sanitation'],\n",
    "        [7, 'Affordable and clean energy'],\n",
    "        [8, 'Decent work and economic growth'],\n",
    "        [9, 'Industry, Innovation and Infrastructure'],\n",
    "        [10, 'Reduced inequality'],\n",
    "        [11, 'Sustainable cities and communities'],\n",
    "        [12, 'Responsible consumption and production'],\n",
    "        [13, 'Climate action'],\n",
    "        [14, 'Life below water'],\n",
    "        [15, 'Life on land']\n",
    "    ]\n",
    "    \n",
    "    cur.executemany(sdg_insert, sdg_mapping)\n",
    "    conn.commit()\n",
    "    \n",
    "    res_prof['SDG'] = res_prof['SDG'].astype(str).str.split('; ')\n",
    "    res_prof = res_prof.explode('SDG')\n",
    "    res_prof.loc[res_prof['SDG'] == 'nan', 'SDG'] = np.nan\n",
    "    \n",
    "    return res_prof\n",
    "\n",
    "res_prof = process_sdg(cur, conn, res_prof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47496955",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-16T08:26:33.942355Z",
     "start_time": "2022-04-16T08:26:33.932722Z"
    }
   },
   "outputs": [],
   "source": [
    "neda_insert = \"\"\"\n",
    "INSERT INTO neda (neda_id, neda_name)\n",
    "VALUES (?, ?)\n",
    "\"\"\"\n",
    "\n",
    "def process_neda(cur, conn):\n",
    "    neda_mapping = [\n",
    "        [1, '\"Malasakit\" Enhancing the Social Fabric'],\n",
    "        [2, '\"Pagbabago\" Reducing Inequality'],\n",
    "        [3, '\"Patuloy na Pag-unlad\" Increasing Growth Potential']\n",
    "    ]\n",
    "    \n",
    "    cur.executemany(neda_insert, neda_mapping)\n",
    "    conn.commit()\n",
    "    \n",
    "process_neda(cur, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb1602b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-16T08:26:33.984778Z",
     "start_time": "2022-04-16T08:26:33.944511Z"
    }
   },
   "outputs": [],
   "source": [
    "journal_insert = \"\"\"\n",
    "INSERT INTO journal (journal_name, volume_no, issue_no, year_published, \n",
    "                     no_citations, scope)\n",
    "VALUES (?, ?, ?, ?, ?, ?)\n",
    "\"\"\"\n",
    "\n",
    "def process_journals(cur, conn, res_prof):\n",
    "    journals = res_prof.loc[:, 'Journal Title':'Local/International']\n",
    "    journals = journals[~journals['Journal Title'].isnull()].drop_duplicates()\n",
    "    journals = journals.values.tolist()\n",
    "    cur.executemany(journal_insert, journals)\n",
    "    conn.commit()\n",
    "\n",
    "    cols = res_prof.loc[:, 'Journal Title':'Local/International'].columns\n",
    "    res_prof['Volume No'] = res_prof['Volume No'].astype(str) \n",
    "    cur.execute('SELECT * FROM journal;')\n",
    "    journal_table = pd.DataFrame(cur.fetchall(), columns=['journal_id'] \n",
    "                                 + cols.tolist())\n",
    "    \n",
    "    res_prof = pd.merge(res_prof, journal_table, \n",
    "                        left_on=cols.tolist(), \n",
    "                        right_on=cols.tolist(), \n",
    "                        how='left')\n",
    "    res_prof = res_prof.drop(cols, axis=1)\n",
    "    return res_prof\n",
    "\n",
    "res_prof = process_journals(cur, conn, res_prof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d68f4a2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-16T08:26:34.387196Z",
     "start_time": "2022-04-16T08:26:33.986722Z"
    }
   },
   "outputs": [],
   "source": [
    "res_stat_insert = \"\"\"\n",
    "INSERT INTO research_status (rs_id, rs_name)\n",
    "VALUES (?, ?)\n",
    "\"\"\"\n",
    "def process_research_status(cur, conn, res_prof):\n",
    "    res_stat_mapping = [\n",
    "        [0, 'Ongoing'],\n",
    "        [1, 'Completed']\n",
    "    ]\n",
    "    cur.executemany(res_stat_insert, res_stat_mapping)\n",
    "    conn.commit()\n",
    "    col = 'Status \\n(Completed/Ongoing)'\n",
    "    res_prof[col] = res_prof[col].str.replace('completed', 'Completed')\n",
    "    res_stat_table = pd.DataFrame(res_stat_mapping, columns=['rs_id', col])\n",
    "    res_prof = pd.merge(res_prof, res_stat_table, \n",
    "                        left_on=col, \n",
    "                        right_on=col, \n",
    "                        how='left')\n",
    "    res_prof = res_prof.drop(col, axis=1)\n",
    "    \n",
    "    return res_prof\n",
    "    \n",
    "res_prof = process_research_status(cur, conn, res_prof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e32a6970",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-16T08:26:34.428734Z",
     "start_time": "2022-04-16T08:26:34.389458Z"
    }
   },
   "outputs": [],
   "source": [
    "budget_source_insert = \"\"\"\n",
    "INSERT INTO budget_source (bs_id, bs_name)\n",
    "VALUES (?, ?)\n",
    "\"\"\"\n",
    "\n",
    "def process_budget_source(cur, conn, res_prof):\n",
    "    bs_mapping = [\n",
    "        [0, 'Internal'],\n",
    "        [1, 'External']\n",
    "    ]\n",
    "    cur.executemany(budget_source_insert, bs_mapping)\n",
    "    conn.commit()\n",
    "    \n",
    "    col = 'Source'\n",
    "    res_prof[col] = res_prof[col].str.split('; ')\n",
    "    res_prof = res_prof.explode(col)\n",
    "    bs_table = pd.DataFrame(bs_mapping, columns=['bs_id', col])\n",
    "    res_prof = pd.merge(res_prof, bs_table, \n",
    "                        left_on=col, \n",
    "                        right_on=col, \n",
    "                        how='left')\n",
    "    res_prof = res_prof.drop(col, axis=1)\n",
    "    return res_prof\n",
    "\n",
    "res_prof = process_budget_source(cur, conn, res_prof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "430fa6ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-16T08:26:34.452035Z",
     "start_time": "2022-04-16T08:26:34.430908Z"
    }
   },
   "outputs": [],
   "source": [
    "funding_agency_insert = \"\"\"\n",
    "INSERT INTO funding_agency (fa_name)\n",
    "VALUES (?)\n",
    "\"\"\"\n",
    "\n",
    "def process_funding_agency(cur, conn, res_prof):\n",
    "    fa_mapping = sorted(res_prof['Funding Agency'].dropna().unique())\n",
    "    for fa in fa_mapping:\n",
    "        cur.execute(funding_agency_insert, tuple([fa]))\n",
    "    conn.commit()\n",
    "    \n",
    "    cur.execute('SELECT * FROM funding_agency;')\n",
    "    fa_table = pd.DataFrame(cur.fetchall(), columns=['fa_id',\n",
    "                                                    'Funding Agency'])\n",
    "    res_prof = pd.merge(res_prof, fa_table, \n",
    "                    left_on='Funding Agency', \n",
    "                    right_on='Funding Agency', \n",
    "                    how='left')\n",
    "    \n",
    "    res_prof = res_prof.drop('Funding Agency', axis=1)\n",
    "    \n",
    "    return res_prof\n",
    "\n",
    "res_prof = process_funding_agency(cur, conn, res_prof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "edc5cbb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-16T08:26:34.476684Z",
     "start_time": "2022-04-16T08:26:34.454292Z"
    }
   },
   "outputs": [],
   "source": [
    "funding_type_insert = \"\"\"\n",
    "INSERT INTO funding_type (ft_name)\n",
    "VALUES (?)\n",
    "\"\"\"\n",
    "\n",
    "def process_funding_type(cur, conn, res_prof):\n",
    "    ft_mapping = sorted(res_prof['Type\\n(Grant, Commissioned)'].dropna()\n",
    "                                                               .unique())\n",
    "    for ft in ft_mapping:\n",
    "        cur.execute(funding_type_insert, tuple([ft]))\n",
    "    conn.commit()\n",
    "    \n",
    "    cur.execute('SELECT * FROM funding_type;')\n",
    "    ft_table = pd.DataFrame(cur.fetchall(), \n",
    "                            columns=['ft_id',\n",
    "                                     'Type\\n(Grant, Commissioned)'])\n",
    "    res_prof = pd.merge(res_prof, ft_table, \n",
    "                    left_on='Type\\n(Grant, Commissioned)', \n",
    "                    right_on='Type\\n(Grant, Commissioned)', \n",
    "                    how='left')\n",
    "    res_prof = res_prof.drop('Type\\n(Grant, Commissioned)', axis=1)\n",
    "    \n",
    "    return res_prof\n",
    "\n",
    "res_prof = process_funding_type(cur, conn, res_prof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1fb783a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-16T08:26:34.555758Z",
     "start_time": "2022-04-16T08:26:34.478825Z"
    }
   },
   "outputs": [],
   "source": [
    "school_insert = \"\"\"\n",
    "INSERT INTO school (school_name, school_abbreviation, \n",
    "                    campus, city, province, region)\n",
    "VALUES (?, ?, ?, ?, ?, ?)\n",
    "\"\"\"\n",
    "\n",
    "def process_school(cur, conn, res_prof):\n",
    "    sch = res_prof.loc[:, 'University (Full Name)':'Region']\n",
    "    cols = sch.columns\n",
    "    for col in cols:\n",
    "        sch[col] = sch[col].astype(str).str.strip()\n",
    "    sch = (sch.drop_duplicates()\n",
    "              .sort_values(by='University (Full Name)'))\n",
    "    cur.executemany(school_insert, sch.values.tolist())\n",
    "    conn.commit()\n",
    "    \n",
    "    cur.execute('SELECT * FROM school;')\n",
    "    school_table = pd.DataFrame(cur.fetchall(), columns=['school_id'] \n",
    "                             + cols.tolist())\n",
    "    \n",
    "    for col in cols:\n",
    "        school_table[col] = school_table[col].astype(str).str.strip()\n",
    "    \n",
    "    cols = cols.tolist()\n",
    "    cols.remove('Region')\n",
    "    res_prof = pd.merge(res_prof.drop('Region',axis=1), school_table, \n",
    "                    left_on=cols, \n",
    "                    right_on=cols, \n",
    "                    how='left')\n",
    "    \n",
    "    res_prof = res_prof.drop(cols + ['Region'], axis=1)\n",
    "\n",
    "    return res_prof\n",
    "    \n",
    "res_prof = process_school(cur, conn, res_prof)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1bf2a860",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-16T08:26:34.610541Z",
     "start_time": "2022-04-16T08:26:34.558061Z"
    }
   },
   "outputs": [],
   "source": [
    "research_profile_insert = \"\"\"\n",
    "INSERT INTO research_profile (research_title, author_id, keywords, \n",
    "                    abstract, year, school_id, sdg_id,\n",
    "                    neda_id, journal_id, allocated_budget,\n",
    "                    bs_id, fa_id, ft_id, rs_id)\n",
    "VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "\"\"\"\n",
    "\n",
    "def process_research_profile(cur, conn, res_prof):\n",
    "    res_prof = res_prof.loc[:, ['Research Title', 'author_id', 'Keywords', \n",
    "                'Abstract', 'Year (YYYY)', 'school_id', 'SDG', \n",
    "                'NEDA Priority Area', 'journal_id', \n",
    "                'Allocated Budget (PH Pesos) 1,000,000.00',\n",
    "                'bs_id', 'fa_id', 'ft_id', 'rs_id']]\n",
    "    \n",
    "    cur.executemany(research_profile_insert, \n",
    "                    res_prof.values.tolist())\n",
    "    \n",
    "    conn.commit()\n",
    "    \n",
    "process_research_profile(cur, conn, res_prof)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
